{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d226a570",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff25aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from pandas_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee4586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b66b9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4453cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic                                           headline  \\\n",
       "0             1  thirtysomething scientists unveil doomsday clo...   \n",
       "1             0  dem rep. totally nails why congress is falling...   \n",
       "2             0  eat your veggies: 9 deliciously different recipes   \n",
       "3             1  inclement weather prevents liar from getting t...   \n",
       "4             1  mother comes pretty close to using word 'strea...   \n",
       "\n",
       "                                        article_link  \n",
       "0  https://www.theonion.com/thirtysomething-scien...  \n",
       "1  https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2  https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3  https://local.theonion.com/inclement-weather-p...  \n",
       "4  https://www.theonion.com/mother-comes-pretty-c...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data \n",
    "path = '/Users/lucialarraona/Desktop/projects_sem2/dtudeeplearning22/Files/Sarcasm_Headlines_Dataset_v2.json'\n",
    "df = pd.read_json(path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8e791",
   "metadata": {},
   "source": [
    "### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c1a151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has a shape of (20033, 3)\n",
      "The testing set has a shape of (8586, 3)\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(df, frac=0.2):\n",
    "    # Get random sample of the dataframe\n",
    "    test = df.sample(frac=frac, axis=0, random_state= 42) # random state to ensure reproductibility of results\n",
    "    # Get everything but the test sample\n",
    "    train = df.drop(index=test.index)\n",
    "    return train, test\n",
    "\n",
    "df_train, df_test = train_test_split(df,frac=0.3)\n",
    "print(f'The training set has a shape of {df_train.shape}')\n",
    "print(f'The testing set has a shape of {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f213b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['headline']\n",
    "X_test = df_test['headline']\n",
    "\n",
    "y_train = df_train['is_sarcastic']\n",
    "y_test = df_test['is_sarcastic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54b47cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = list(df['is_sarcastic'].unique())\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67040268",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "- Distilled-Bert (a smaller version of Bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b14f2",
   "metadata": {},
   "source": [
    "####  Define model and max_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5287fcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-name (based on hugging-face library)\n",
    "model_name = \"bert-base-uncased\"\n",
    "# max sequence length for each document/sentence sample (headlines are much shorter, we'll change it)\n",
    "max_length = 512 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e36682",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f32a6640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e66bbc385cc425ab85c5d25ecb9e26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afb80f8a7e44405b233b1383fd1111a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hugging Face has its own tokenizer for the transformer: Load the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bf5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the dataset, truncate when passed `max_length`, and pad with 0's when less than `max_length`\n",
    "train_encodings = X_train.apply(lambda x: tokenizer(x, truncation=True,padding=True, max_length=max_length))\n",
    "test_encodings = X_test.apply(lambda x: tokenizer(x, truncation=True,padding=True, max_length=max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9b0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset with the tokenized input(headlines) and the labels\n",
    "class NewsHeadlinesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = NewsHeadlinesDataset(train_encodings, y_train)\n",
    "test_dataset = NewsHeadlinesDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53f3cc",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb9585b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e94557206441d1a9dcbf81871a0d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl Kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. Revise el código de las celdas para identificar una posible causa del error. Haga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. Vea el [registro] de Jupyter (command:jupyter.viewOutput) para obtener más detalles."
     ]
    }
   ],
   "source": [
    "# Training with Trainer function from HuggingFace\n",
    "\n",
    "# Load the model and pass to CUDA\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics for evaluating the classification model and pass it to the Trainer object\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  # calculate accuracy using sklearn's function\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\n",
    "      'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5100c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=20,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    load_best_model_at_end=True,     # load the best model when finished training (default metric is loss)\n",
    "    # but you can specify `metric_for_best_model` argument to change to accuracy or other metric\n",
    "    logging_steps=400,               # log & save weights each logging_steps\n",
    "    save_steps=400,\n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3f939",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3317bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model after training\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35feaa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return target_names[probs.argmax()]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab23fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model_path = \"Files/saved_models/model_name\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a453518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "dd67d5026f11b9bb6db4da73e555964d530e0e075e26b3ee03294e4d81583c06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
